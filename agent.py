from dotenv import load_dotenv
import logging
import json
import asyncio
from livekit import agents
from livekit.agents import AgentSession, Agent, RoomInputOptions, llm, RoomOutputOptions
from livekit.plugins import (
    google,
    openai,
    noise_cancellation,
)
from livekit.plugins.openai.realtime.utils import TurnDetection
from livekit.agents import mcp as mcp_client
from prompts import AGENT_INSTRUCTION, SESSION_INSTRUCTION
from tools import (
    get_weather,
    search_web,
    qa_find_answer,
    qa_search_by_tag,
    qa_search_questions,
    qa_list_tags,
)
from log_config import setup_logging

load_dotenv()

# è¨­å®šæ—¥èªŒï¼ˆä½¿ç”¨çµ±ä¸€é…ç½®ï¼‰
setup_logging(level=logging.INFO, disable_duplicate=True)
agent_logger = logging.getLogger("core.agent")


class Assistant(Agent):
    def __init__(self) -> None:
        super().__init__(
            # llm=google.beta.realtime.RealtimeModel(
            #     voice="Aoede",
            #     temperature=0.8,
            # ),
            instructions=AGENT_INSTRUCTION,
            llm=openai.realtime.RealtimeModel(
                voice="marin",  # é è¨­ç‚º marin, å¦æä¾›ä»¥ä¸‹é¸æ“‡ alloy, ash, ballad, coral, echo, sage, shimmer, verse, cedar
                temperature=0.8,
                speed=1.2,
                turn_detection=TurnDetection(  # âœ… å•Ÿç”¨ä¼ºæœå™¨ç«¯èªéŸ³æª¢æ¸¬
                    type="server_vad",
                    threshold=0.3,  # âœ… é™ä½é–¾å€¼ä½¿å…¶æ›´å®¹æ˜“è§¸ç™¼ï¼ˆå¾ 0.5 â†’ 0.3ï¼‰
                    prefix_padding_ms=300,
                    silence_duration_ms=500,
                ),
            ),
            tools=[
                get_weather,
                # search_web,
                qa_find_answer,
                qa_search_by_tag,
                qa_search_questions,
                qa_list_tags,
            ],
            # âœ… é—œéµï¼šé€£åˆ°æœ¬åœ°æˆ–é ç«¯ MCP Serverï¼›å¯ä¸¦åˆ—å¤šå€‹
            # mcp_servers=[
            #     # 1) è‹¥ä½¿ç”¨ stdio å•Ÿå‹•ï¼ˆåŒæ©Ÿã€ä»¥ subprocess æ–¹å¼ï¼‰ï¼š
            #     # mcp_client.MCPServerStdio(
            #     #     command=sys.executable,
            #     #     args=[str(Path(__file__).with_name("mcp_server.py"))]
            #     # ),
            #     # 2) è‹¥ä½¿ç”¨ HTTP/SSE æ–¹å¼ï¼ˆè«‹æ›¿æ› URL ç‚ºä½ çš„éƒ¨ç½²ä½ç½®ï¼‰ï¼š
            #     # mcp_client.MCPServerHTTP("http://localhost:8000"),
            #     mcp_client.MCPServerHTTP("http://localhost:9000/sse", timeout=10),
            #     # 3) äº¦å¯ä½¿ç”¨ Streamable HTTPï¼ˆè¦–ä¼ºæœå™¨å‹æ…‹è€Œå®šï¼‰
            #     # mcp_client.MCPServerStreamableHTTP("http://localhost:8000"),
            # ],
        )

    # ç§»é™¤ on_enter å’Œ on_exitï¼Œé¿å…æå‰çµæŸ session
    # async def on_enter(self):
    #     agent_logger.info("Assistant agent has called when the task is entered")

    # async def on_exit(self):
    #     agent_logger.info("Assistant agent has called when the task is exited.")

    # ä¿ç•™é€™å€‹æ–¹æ³•ä¾†è¨˜éŒ„ç”¨æˆ¶è¨Šæ¯
    # async def on_user_turn_completed(
    #     self, turn_ctx: llm.ChatContext, new_message: llm.ChatMessage
    # ):
    #     agent_logger.info(
    #         f"Called when the user has finished speaking, and the LLM is about to respond. New message: {new_message.text[:50]}..."
    #     )


async def entrypoint(ctx: agents.JobContext):
    agent_logger.info(f"Entrypoint called with room: {ctx.room}")
    agent_logger.info(f"Room name: {getattr(ctx.room, 'name', 'Not connected yet')}")

    # å…ˆé€£æ¥åˆ°æˆ¿é–“
    await ctx.connect()
    agent_logger.info("âœ… Connected to room")

    # è¨­å®š Agent Metadataï¼ˆè®“å‰ç«¯å¯ä»¥è­˜åˆ¥ï¼‰
    try:
        # ä½¿ç”¨ set_metadata è€Œä¸æ˜¯ update_metadata
        await ctx.room.local_participant.set_metadata(
            json.dumps({"role": "agent", "name": "å˜‰ç¾©å®¢æœ AI"})
        )
        agent_logger.info("âœ… Agent metadata set successfully")
    except Exception as e:
        agent_logger.error(f"Failed to set metadata: {e}")
        # å¦‚æœ set_metadata ä¹Ÿä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦å…¶ä»–æ–¹å¼è¨­å®š
        agent_logger.info(f"Available methods: {dir(ctx.room.local_participant)}")

    session = AgentSession()

    # ç›£è½åƒèˆ‡è€…åŠ å…¥äº‹ä»¶
    participant_greeted = False

    def on_participant_connected(participant):
        nonlocal participant_greeted
        agent_logger.info(f"ğŸ‘¤ Participant connected: {participant.identity}")
        agent_logger.info(f"   - SID: {participant.sid}")
        agent_logger.info(f"   - Is local: {participant.is_local}")
        agent_logger.info(f"   - Metadata: {participant.metadata}")

        if not participant.is_local and not participant_greeted:
            agent_logger.info(f"âœ… User joined (non-local): {participant.identity}")
            participant_greeted = True
            # ç”¨æˆ¶åŠ å…¥æ™‚å¯ä»¥é¸æ“‡æ€§åœ°ç”Ÿæˆæ­¡è¿è¨Šæ¯
            # ä½†é€šå¸¸ç­‰ç”¨æˆ¶å…ˆèªªè©±æ¯”è¼ƒè‡ªç„¶

    def on_participant_disconnected(participant):
        agent_logger.info(f"ğŸ‘¤ Participant disconnected: {participant.identity}")
        # RemoteParticipant doesn't have is_local attribute
        agent_logger.info(f"   - Participant type: {type(participant).__name__}")

    ctx.room.on("participant_connected", on_participant_connected)
    ctx.room.on("participant_disconnected", on_participant_disconnected)

    # ç›£è½æˆ¿é–“ç‹€æ…‹è®ŠåŒ–
    def on_connection_state_changed(state):
        agent_logger.info(f"ğŸ“¡ Connection state changed: {state}")

    ctx.room.on("connection_state_changed", on_connection_state_changed)

    # è¨‚é–± ASR è½‰éŒ„äº‹ä»¶
    def on_user_transcribed(event):
        event_type = "asr_final" if event.is_final else "asr_interim"
        agent_logger.info(f"[ASR] User said ({event_type}): {event.transcript}")

        # âœ… ç™¼é€ ASR æ–‡å­—åˆ°å‰ç«¯ï¼ˆåªç™¼é€ final çµæœï¼‰
        if event.is_final and event.transcript.strip():
            try:
                asyncio.create_task(
                    ctx.room.local_participant.publish_data(
                        json.dumps({
                            "type": "transcription",
                            "role": "user",
                            "text": event.transcript,
                            "is_final": True
                        }).encode('utf-8'),
                        reliable=True
                    )
                )
                agent_logger.info(f"ğŸ“¤ Sent user transcription to client: {event.transcript}")
            except Exception as e:
                agent_logger.error(f"âŒ Failed to send transcription: {e}")

    # ç›£è½ session éŸ³è¨Šè¼¸å…¥äº‹ä»¶
    def on_input_audio_buffer_committed(event):
        agent_logger.info(f"ğŸ¤ Audio input buffer committed")

    def on_input_audio_buffer_speech_started(event):
        agent_logger.info(f"ğŸ—£ï¸ Speech started detected")

    def on_input_audio_buffer_speech_stopped(event):
        agent_logger.info(f"ğŸ¤ Speech stopped detected")

    # âœ… è¨ºæ–·ç”¨ï¼šç›£è½ OpenAI Realtime API åŸå§‹äº‹ä»¶
    def on_openai_server_event(event):
        event_type = event.get('type', '') if isinstance(event, dict) else str(type(event).__name__)
        # åªè¨˜éŒ„é‡è¦äº‹ä»¶ï¼Œé¿å… log éå¤š
        if 'delta' in event_type or 'done' in event_type:
            agent_logger.info(f"ğŸ”” OpenAI Event: {event_type}")

    session.on("openai_server_event_received", on_openai_server_event)

    # ç›£è½ Agent å›æ‡‰äº‹ä»¶
    def on_agent_speech(event):
        agent_logger.info(f"ğŸ”Š Agent speech event: {type(event).__name__}")

    # âœ… ç›£è½æ‰€æœ‰å¯èƒ½çš„ session äº‹ä»¶ï¼ˆè¨ºæ–·ç”¨ï¼‰
    def on_any_session_event(event):
        event_name = type(event).__name__
        agent_logger.info(f"ğŸ“¡ Session event: {event_name}")
        if hasattr(event, '__dict__'):
            agent_logger.info(f"   Event data: {event.__dict__}")

    session.on("user_input_transcribed", on_user_transcribed)
    session.on("input_audio_buffer_committed", on_input_audio_buffer_committed)
    session.on("input_audio_buffer_speech_started", on_input_audio_buffer_speech_started)
    session.on("input_audio_buffer_speech_stopped", on_input_audio_buffer_speech_stopped)
    session.on("agent_speech", on_agent_speech)

    # å˜—è©¦ç›£è½æ›´å¤šå¯èƒ½çš„äº‹ä»¶
    try:
        session.on("user_speech_committed", lambda e: agent_logger.info(f"ğŸ¯ User speech committed: {e}"))
        session.on("audio_input_started", lambda e: agent_logger.info(f"ğŸ™ï¸ Audio input started"))
        session.on("audio_input_stopped", lambda e: agent_logger.info(f"ğŸ™ï¸ Audio input stopped"))
    except Exception as e:
        agent_logger.debug(f"Some event listeners not available: {e}")

    # ç›£è½éŸ³è¨Šè»Œé“è¨‚é–±äº‹ä»¶
    def on_track_subscribed(track, publication, participant):
        agent_logger.info(f"ğŸµ Track subscribed from {participant.identity}: {track.kind}")
        agent_logger.info(f"   Track SID: {track.sid}")
        agent_logger.info(f"   Publication SID: {publication.sid}")
        if track.kind == "audio":
            agent_logger.info(f"   Audio track received, enabled: {track.enabled}")

            # âœ… ç›£è½éŸ³è¨Šè»Œé“çš„è³‡æ–™æµï¼ˆè¨ºæ–·ç”¨ï¼‰
            async def log_audio_frames():
                agent_logger.info(f"ğŸ“Š Starting audio frame monitoring for {participant.identity}")
                frame_count = 0
                async for frame in track:
                    frame_count += 1
                    if frame_count % 100 == 0:  # æ¯ 100 å¹€è¨˜éŒ„ä¸€æ¬¡
                        agent_logger.info(f"ğŸ¤ Received {frame_count} audio frames from {participant.identity}")

            # å•Ÿå‹•ç›£æ§ä»»å‹™
            asyncio.create_task(log_audio_frames())

    # ç›£è½è»Œé“ç™¼å¸ƒäº‹ä»¶ï¼ˆæ›´æ—©æœŸçš„äº‹ä»¶ï¼‰
    def on_track_published(publication, participant):
        agent_logger.info(f"ğŸ“¢ Track published from {participant.identity}: {publication.kind}")
        agent_logger.info(f"   Publication SID: {publication.sid}")
        agent_logger.info(f"   Is subscribed: {publication.subscribed}")

    ctx.room.on("track_subscribed", on_track_subscribed)
    ctx.room.on("track_published", on_track_published)

    # è¨‚é–± LLM ç”Ÿæˆäº‹ä»¶ï¼ˆå³æ™‚é¡¯ç¤º LLM è¼¸å‡ºï¼‰
    def on_agent_started_speaking(event):
        """ç•¶ LLM é–‹å§‹ç”Ÿæˆå›æ‡‰æ™‚è§¸ç™¼ï¼ˆåœ¨ TTS ä¹‹å‰ï¼‰"""
        if hasattr(event, 'content'):
            agent_logger.info(f"[LLM] Assistant generating: {event.content}")

    session.on("agent_started_speaking", on_agent_started_speaking)

    # è¨‚é–±å°è©±é …ç›®æ–°å¢äº‹ä»¶ï¼ˆåƒ…ç”¨æ–¼è¨˜éŒ„ï¼‰
    def on_conversation_item(event):
        if hasattr(event, 'item') and hasattr(event.item, 'role'):
            if event.item.role == 'assistant':
                content = event.item.content if hasattr(event.item, 'content') else ''
                text = ' '.join(content) if isinstance(content, list) else content
                agent_logger.info(f"[Agent] Response complete: {text[:100]}...")

    session.on("conversation_item_added", on_conversation_item)

    # è¨˜éŒ„æˆ¿é–“ç•¶å‰ç‹€æ…‹
    agent_logger.info(f"ğŸ“Š Room state before session.start:")
    agent_logger.info(f"   - Room name: {ctx.room.name}")
    # ctx.room.sid is a coroutine, need to await it
    room_sid = await ctx.room.sid
    agent_logger.info(f"   - Room SID: {room_sid}")
    agent_logger.info(f"   - Local participant: {ctx.room.local_participant.identity}")
    agent_logger.info(f"   - Remote participants count: {len(ctx.room.remote_participants)}")
    agent_logger.info(f"   - Connection state: {ctx.room.connection_state}")

    # åˆ—å‡ºæ‰€æœ‰é ç«¯åƒèˆ‡è€…
    if ctx.room.remote_participants:
        for identity, participant in ctx.room.remote_participants.items():
            agent_logger.info(f"   - Remote participant: {identity} (SID: {participant.sid})")

    # å•Ÿå‹• sessionï¼ˆsession.start æœƒä¿æŒé‹è¡Œç›´åˆ°æˆ¿é–“é—œé–‰ï¼‰
    # âœ… é—œéµä¿®æ­£ï¼šèª¿æ•´éŸ³è¨Šé…ç½®
    agent_logger.info("ğŸš€ Starting AgentSession...")
    await session.start(
        room=ctx.room,
        agent=Assistant(),
        room_input_options=RoomInputOptions(
            audio_enabled=True,          # âœ… æ˜ç¢ºå•Ÿç”¨éŸ³è¨Šè¼¸å…¥ï¼ˆæ¥æ”¶ç”¨æˆ¶èªéŸ³ï¼‰
            video_enabled=False,         # âœ… é—œé–‰è¦–è¨Šç¯€çœè³‡æº
            noise_cancellation=noise_cancellation.BVC(),  # âœ… ä¿ç•™ BVC é™å™ª
            pre_connect_audio_timeout=10.0,  # âœ… å¢åŠ è¶…æ™‚æ™‚é–“ï¼ˆé è¨­ 3 ç§’å¯èƒ½å¤ªçŸ­ï¼‰
        ),
        room_output_options=RoomOutputOptions(
            audio_enabled=True,          # âœ… ç¢ºèªå•Ÿç”¨éŸ³è¨Šè¼¸å‡ºï¼ˆTTSï¼‰
            transcription_enabled=True,  # å•Ÿç”¨è½‰éŒ„
        ),
    )
    agent_logger.info("âœ… Session started successfully")

    # è¨˜éŒ„æˆ¿é–“ç‹€æ…‹ after session.start
    agent_logger.info(f"ğŸ“Š Room state after session.start:")
    agent_logger.info(f"   - Connection state: {ctx.room.connection_state}")
    agent_logger.info(f"   - Remote participants: {[p.identity for p in ctx.room.remote_participants.values()]}")

    # æª¢æŸ¥å·²å­˜åœ¨çš„è»Œé“ä¸¦æ‰‹å‹•å•Ÿå‹•éŸ³è¨Šç›£æ§
    for identity, participant in ctx.room.remote_participants.items():
        agent_logger.info(f"ğŸ“‹ Checking existing tracks for {identity}:")
        agent_logger.info(f"   - Track publications count: {len(participant.track_publications)}")
        for sid, publication in participant.track_publications.items():
            kind = publication.kind if hasattr(publication, 'kind') else 'unknown'
            agent_logger.info(f"   - Track {kind}: SID={sid}, subscribed={publication.subscribed}")
            if publication.track:
                track = publication.track
                agent_logger.info(f"     â€¢ Actual track SID: {track.sid}")
                agent_logger.info(f"     â€¢ Track enabled: {track.enabled if hasattr(track, 'enabled') else 'N/A'}")

                # âœ… æ‰‹å‹•è™•ç†å·²å­˜åœ¨çš„éŸ³è¨Šè»Œé“ï¼ˆå› ç‚º track_subscribed äº‹ä»¶ä¸æœƒå†æ¬¡è§¸ç™¼ï¼‰
                if kind == "audio":
                    agent_logger.info(f"ğŸ¯ Found existing audio track, starting monitoring...")

                    async def log_audio_frames():
                        agent_logger.info(f"ğŸ“Š Starting audio frame monitoring for existing track: {identity}")
                        frame_count = 0
                        try:
                            async for frame in track:
                                frame_count += 1
                                if frame_count % 100 == 0:  # æ¯ 100 å¹€è¨˜éŒ„ä¸€æ¬¡
                                    agent_logger.info(f"ğŸ¤ Received {frame_count} audio frames from {identity}")
                        except Exception as e:
                            agent_logger.error(f"âŒ Error monitoring audio frames: {e}")

                    # å•Ÿå‹•ç›£æ§ä»»å‹™
                    asyncio.create_task(log_audio_frames())

    # âœ… å•Ÿå‹• OpenAI Realtime å°è©±å¾ªç’°ï¼ˆå¿…é ˆèª¿ç”¨æ‰èƒ½æ¿€æ´» LLMï¼‰
    await session.generate_reply(
        instructions=SESSION_INSTRUCTION,
    )


if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    logging.info("Starting LiveKit agent...")
    agents.cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))
